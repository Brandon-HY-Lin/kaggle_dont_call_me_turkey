{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using attention model\n",
    "\n",
    "Reference: https://www.kaggle.com/truocpham/oob-cuda-gru-attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "import sklearn\n",
    "import keras\n",
    "\n",
    "#### BEGIN Attention Model ####\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "#### END Attention Model ####\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train = './datasets/train.json'\n",
    "filename_test = './datasets/test.json'\n",
    "\n",
    "train = pd.read_json(filename_train)\n",
    "test = pd.read_json(filename_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>is_turkey</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "      <th>vid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>kDCk3hLIVXo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>DPcGzqHoo7Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>7yM63MTHh5k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...</td>\n",
       "      <td>520</td>\n",
       "      <td>1</td>\n",
       "      <td>510</td>\n",
       "      <td>luG3RmUAxxM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PIm3cjxTpOk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     audio_embedding  \\\n",
       "0  [[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...   \n",
       "1  [[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...   \n",
       "2  [[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...   \n",
       "3  [[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...   \n",
       "4  [[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...   \n",
       "\n",
       "   end_time_seconds_youtube_clip  is_turkey  start_time_seconds_youtube_clip  \\\n",
       "0                             70          0                               60   \n",
       "1                             40          1                               30   \n",
       "2                            240          1                              230   \n",
       "3                            520          1                              510   \n",
       "4                             10          0                                0   \n",
       "\n",
       "        vid_id  \n",
       "0  kDCk3hLIVXo  \n",
       "1  DPcGzqHoo7Y  \n",
       "2  7yM63MTHh5k  \n",
       "3  luG3RmUAxxM  \n",
       "4  PIm3cjxTpOk  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrive Audio Embedding and Flatten it into 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.DataFrame(list(train['audio_embedding'].map(lambda x: chain.from_iterable(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195, 1280)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1270</th>\n",
       "      <th>1271</th>\n",
       "      <th>1272</th>\n",
       "      <th>1273</th>\n",
       "      <th>1274</th>\n",
       "      <th>1275</th>\n",
       "      <th>1276</th>\n",
       "      <th>1277</th>\n",
       "      <th>1278</th>\n",
       "      <th>1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172</td>\n",
       "      <td>34</td>\n",
       "      <td>216</td>\n",
       "      <td>110</td>\n",
       "      <td>208</td>\n",
       "      <td>46</td>\n",
       "      <td>95</td>\n",
       "      <td>66</td>\n",
       "      <td>161</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169</td>\n",
       "      <td>20</td>\n",
       "      <td>165</td>\n",
       "      <td>102</td>\n",
       "      <td>205</td>\n",
       "      <td>62</td>\n",
       "      <td>110</td>\n",
       "      <td>103</td>\n",
       "      <td>211</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148</td>\n",
       "      <td>8</td>\n",
       "      <td>138</td>\n",
       "      <td>60</td>\n",
       "      <td>237</td>\n",
       "      <td>48</td>\n",
       "      <td>121</td>\n",
       "      <td>108</td>\n",
       "      <td>145</td>\n",
       "      <td>177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>88</td>\n",
       "      <td>171</td>\n",
       "      <td>71</td>\n",
       "      <td>47</td>\n",
       "      <td>90</td>\n",
       "      <td>179</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162</td>\n",
       "      <td>17</td>\n",
       "      <td>187</td>\n",
       "      <td>111</td>\n",
       "      <td>211</td>\n",
       "      <td>105</td>\n",
       "      <td>92</td>\n",
       "      <td>67</td>\n",
       "      <td>203</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  1270  \\\n",
       "0   172    34   216   110   208    46    95    66   161   125  ...   0.0   \n",
       "1   169    20   165   102   205    62   110   103   211   187  ...   0.0   \n",
       "2   148     8   138    60   237    48   121   108   145   177  ...   0.0   \n",
       "3   151     0   162    88   171    71    47    90   179   190  ...   0.0   \n",
       "4   162    17   187   111   211   105    92    67   203   152  ...  62.0   \n",
       "\n",
       "    1271   1272   1273   1274   1275   1276   1277   1278   1279  \n",
       "0  135.0  133.0  151.0    0.0    3.0  206.0  101.0  104.0  255.0  \n",
       "1    0.0  119.0  205.0   27.0  151.0  226.0   44.0    0.0  255.0  \n",
       "2   62.0   79.0  204.0    0.0   74.0  243.0  255.0   95.0  255.0  \n",
       "3  255.0  207.0   52.0  178.0  129.0  186.0    0.0    0.0  255.0  \n",
       "4  224.0   15.0  172.0    0.0    2.0  255.0  144.0   34.0  255.0  \n",
       "\n",
       "[5 rows x 1280 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check whether NULL Cell exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = [k for k in train['audio_embedding']]\n",
    "test_data = test['audio_embedding'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195\n",
      "1196\n"
     ]
    }
   ],
   "source": [
    "print(len(xtrain))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = train['is_turkey'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Min/Max Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(features) for features in xtrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([len(features) for features in xtrain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pad audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(xtrain, maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195, 10, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(x_train).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert ytrain to np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delcare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model w/o Bidirectional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0717 12:44:58.951398 140206139774656 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0717 12:44:58.969661 140206139774656 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0717 12:44:59.040005 140206139774656 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0717 12:44:59.054923 140206139774656 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0717 12:44:59.158486 140206139774656 deprecation.py:506] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0717 12:44:59.353256 140206139774656 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0717 12:44:59.369686 140206139774656 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0717 12:44:59.373767 140206139774656 deprecation.py:323] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 10, 128)           512       \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 10, 128)           98688     \n",
      "_________________________________________________________________\n",
      "attention_1 (Attention)      (None, 128)               138       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 99,467\n",
      "Trainable params: 99,211\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(10, 128)))\n",
    "#     model.add(Bidirectional(RNN(64, activation='relu', return_sequences=True)))\n",
    "#     model.add(Bidirectional(GRU(128, dropout=0.4, recurrent_dropout=0.4, activation='relu', return_sequences=True)))\n",
    "    model.add(GRU(128, dropout=0.4, recurrent_dropout=0.4, activation='relu', return_sequences=True))\n",
    "    model.add(Attention(10))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "input_dim = x_train.shape\n",
    "# model = get_model(input_dim)\n",
    "model = get_model()\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1074 samples, validate on 121 samples\n",
      "Epoch 1/16\n",
      "1074/1074 [==============================] - 0s 209us/step - loss: 0.1219 - acc: 0.9590 - val_loss: 0.1138 - val_acc: 0.9669\n",
      "Epoch 2/16\n",
      "1074/1074 [==============================] - 0s 242us/step - loss: 0.1178 - acc: 0.9553 - val_loss: 0.1121 - val_acc: 0.9669\n",
      "Epoch 3/16\n",
      "1074/1074 [==============================] - 0s 202us/step - loss: 0.1089 - acc: 0.9590 - val_loss: 0.1116 - val_acc: 0.9669\n",
      "Epoch 4/16\n",
      "1074/1074 [==============================] - 0s 196us/step - loss: 0.1154 - acc: 0.9581 - val_loss: 0.1116 - val_acc: 0.9669\n",
      "Epoch 5/16\n",
      "1074/1074 [==============================] - 0s 233us/step - loss: 0.1011 - acc: 0.9628 - val_loss: 0.1117 - val_acc: 0.9669\n",
      "Epoch 6/16\n",
      "1074/1074 [==============================] - 0s 196us/step - loss: 0.1038 - acc: 0.9590 - val_loss: 0.1113 - val_acc: 0.9669\n",
      "Epoch 7/16\n",
      "1074/1074 [==============================] - 0s 195us/step - loss: 0.1019 - acc: 0.9628 - val_loss: 0.1116 - val_acc: 0.9669\n",
      "Epoch 8/16\n",
      "1074/1074 [==============================] - 0s 200us/step - loss: 0.0913 - acc: 0.9665 - val_loss: 0.1124 - val_acc: 0.9669\n",
      "Epoch 9/16\n",
      "1074/1074 [==============================] - 0s 194us/step - loss: 0.0935 - acc: 0.9655 - val_loss: 0.1135 - val_acc: 0.9669\n",
      "Epoch 10/16\n",
      "1074/1074 [==============================] - 0s 200us/step - loss: 0.0853 - acc: 0.9702 - val_loss: 0.1158 - val_acc: 0.9669\n",
      "Epoch 11/16\n",
      "1074/1074 [==============================] - 0s 193us/step - loss: 0.0991 - acc: 0.9646 - val_loss: 0.1180 - val_acc: 0.9669\n",
      "Epoch 12/16\n",
      "1074/1074 [==============================] - 0s 196us/step - loss: 0.0961 - acc: 0.9628 - val_loss: 0.1189 - val_acc: 0.9669\n",
      "Epoch 13/16\n",
      "1074/1074 [==============================] - 0s 195us/step - loss: 0.0856 - acc: 0.9609 - val_loss: 0.1192 - val_acc: 0.9669\n",
      "Epoch 14/16\n",
      "1074/1074 [==============================] - 0s 197us/step - loss: 0.0894 - acc: 0.9702 - val_loss: 0.1186 - val_acc: 0.9669\n",
      "Epoch 15/16\n",
      "1074/1074 [==============================] - 0s 201us/step - loss: 0.0770 - acc: 0.9749 - val_loss: 0.1165 - val_acc: 0.9669\n",
      "Epoch 16/16\n",
      "1074/1074 [==============================] - 0s 198us/step - loss: 0.0835 - acc: 0.9665 - val_loss: 0.1152 - val_acc: 0.9669\n",
      "\n",
      "Fold 0: score=0.9909859154929578\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/16\n",
      "1075/1075 [==============================] - 0s 198us/step - loss: 0.0978 - acc: 0.9665 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 0.0842 - acc: 0.9684 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1075/1075 [==============================] - 0s 199us/step - loss: 0.0803 - acc: 0.9712 - val_loss: 0.0164 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1075/1075 [==============================] - 0s 194us/step - loss: 0.0858 - acc: 0.9702 - val_loss: 0.0151 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1075/1075 [==============================] - 0s 195us/step - loss: 0.0724 - acc: 0.9730 - val_loss: 0.0145 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1075/1075 [==============================] - 0s 192us/step - loss: 0.0803 - acc: 0.9702 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 0.0691 - acc: 0.9795 - val_loss: 0.0151 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1075/1075 [==============================] - 0s 197us/step - loss: 0.0763 - acc: 0.9712 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1075/1075 [==============================] - 0s 198us/step - loss: 0.0720 - acc: 0.9674 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1075/1075 [==============================] - 0s 201us/step - loss: 0.0829 - acc: 0.9702 - val_loss: 0.0185 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1075/1075 [==============================] - 0s 194us/step - loss: 0.0784 - acc: 0.9702 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1075/1075 [==============================] - 0s 205us/step - loss: 0.0758 - acc: 0.9758 - val_loss: 0.0205 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1075/1075 [==============================] - 0s 203us/step - loss: 0.0744 - acc: 0.9749 - val_loss: 0.0203 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1075/1075 [==============================] - 0s 194us/step - loss: 0.0659 - acc: 0.9777 - val_loss: 0.0217 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1075/1075 [==============================] - 0s 195us/step - loss: 0.0689 - acc: 0.9786 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1075/1075 [==============================] - 0s 193us/step - loss: 0.0722 - acc: 0.9721 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "\n",
      "Fold 1: score=1.0\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/16\n",
      "1075/1075 [==============================] - 0s 192us/step - loss: 0.0636 - acc: 0.9795 - val_loss: 0.0302 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1075/1075 [==============================] - 0s 198us/step - loss: 0.0613 - acc: 0.9823 - val_loss: 0.0306 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1075/1075 [==============================] - 0s 197us/step - loss: 0.0602 - acc: 0.9833 - val_loss: 0.0324 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1075/1075 [==============================] - 0s 198us/step - loss: 0.0580 - acc: 0.9814 - val_loss: 0.0307 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 0.0558 - acc: 0.9805 - val_loss: 0.0320 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1075/1075 [==============================] - 0s 202us/step - loss: 0.0519 - acc: 0.9833 - val_loss: 0.0336 - val_acc: 0.9917\n",
      "Epoch 7/16\n",
      "1075/1075 [==============================] - 0s 197us/step - loss: 0.0490 - acc: 0.9833 - val_loss: 0.0325 - val_acc: 0.9917\n",
      "Epoch 8/16\n",
      "1075/1075 [==============================] - 0s 194us/step - loss: 0.0478 - acc: 0.9777 - val_loss: 0.0272 - val_acc: 0.9917\n",
      "Epoch 9/16\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 0.0687 - acc: 0.9777 - val_loss: 0.0214 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1075/1075 [==============================] - 0s 194us/step - loss: 0.0661 - acc: 0.9730 - val_loss: 0.0203 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 0.0472 - acc: 0.9814 - val_loss: 0.0334 - val_acc: 0.9833\n",
      "Epoch 12/16\n",
      "1075/1075 [==============================] - 0s 193us/step - loss: 0.0501 - acc: 0.9851 - val_loss: 0.0531 - val_acc: 0.9833\n",
      "Epoch 13/16\n",
      "1075/1075 [==============================] - 0s 194us/step - loss: 0.0460 - acc: 0.9842 - val_loss: 0.0431 - val_acc: 0.9833\n",
      "Epoch 14/16\n",
      "1075/1075 [==============================] - 0s 192us/step - loss: 0.0483 - acc: 0.9833 - val_loss: 0.0309 - val_acc: 0.9917\n",
      "Epoch 15/16\n",
      "1075/1075 [==============================] - 0s 197us/step - loss: 0.0491 - acc: 0.9814 - val_loss: 0.0249 - val_acc: 0.9917\n",
      "Epoch 16/16\n",
      "1075/1075 [==============================] - 0s 190us/step - loss: 0.0447 - acc: 0.9814 - val_loss: 0.0274 - val_acc: 0.9917\n",
      "\n",
      "Fold 2: score=1.0\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/16\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 0.0442 - acc: 0.9870 - val_loss: 0.0234 - val_acc: 0.9833\n",
      "Epoch 2/16\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 0.0415 - acc: 0.9860 - val_loss: 0.0243 - val_acc: 0.9833\n",
      "Epoch 3/16\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 0.0411 - acc: 0.9879 - val_loss: 0.0251 - val_acc: 0.9833\n",
      "Epoch 4/16\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 0.0436 - acc: 0.9833 - val_loss: 0.0253 - val_acc: 0.9833\n",
      "Epoch 5/16\n",
      "1075/1075 [==============================] - 0s 191us/step - loss: 0.0415 - acc: 0.9833 - val_loss: 0.0245 - val_acc: 0.9833\n",
      "Epoch 6/16\n",
      "1075/1075 [==============================] - 0s 195us/step - loss: 0.0399 - acc: 0.9860 - val_loss: 0.0236 - val_acc: 0.9833\n",
      "Epoch 7/16\n",
      "1075/1075 [==============================] - 0s 193us/step - loss: 0.0373 - acc: 0.9823 - val_loss: 0.0238 - val_acc: 0.9833\n",
      "Epoch 8/16\n",
      "1075/1075 [==============================] - 0s 195us/step - loss: 0.0363 - acc: 0.9898 - val_loss: 0.0242 - val_acc: 0.9833\n",
      "Epoch 9/16\n",
      "1075/1075 [==============================] - 0s 194us/step - loss: 0.0457 - acc: 0.9833 - val_loss: 0.0282 - val_acc: 0.9833\n",
      "Epoch 10/16\n",
      "1075/1075 [==============================] - 0s 191us/step - loss: 0.0340 - acc: 0.9870 - val_loss: 0.0295 - val_acc: 0.9833\n",
      "Epoch 11/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075/1075 [==============================] - 0s 188us/step - loss: 0.0421 - acc: 0.9814 - val_loss: 0.0271 - val_acc: 0.9833\n",
      "Epoch 12/16\n",
      "1075/1075 [==============================] - 0s 192us/step - loss: 0.0388 - acc: 0.9879 - val_loss: 0.0234 - val_acc: 0.9833\n",
      "Epoch 13/16\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 0.0347 - acc: 0.9870 - val_loss: 0.0235 - val_acc: 0.9833\n",
      "Epoch 14/16\n",
      "1075/1075 [==============================] - 0s 194us/step - loss: 0.0385 - acc: 0.9851 - val_loss: 0.0256 - val_acc: 0.9833\n",
      "Epoch 15/16\n",
      "1075/1075 [==============================] - 0s 198us/step - loss: 0.0303 - acc: 0.9888 - val_loss: 0.0274 - val_acc: 0.9833\n",
      "Epoch 16/16\n",
      "1075/1075 [==============================] - 0s 197us/step - loss: 0.0359 - acc: 0.9860 - val_loss: 0.0287 - val_acc: 0.9833\n",
      "\n",
      "Fold 3: score=0.9997125610807703\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0316 - acc: 0.9861 - val_loss: 0.0198 - val_acc: 0.9916\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0314 - acc: 0.9907 - val_loss: 0.0204 - val_acc: 0.9916\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0367 - acc: 0.9870 - val_loss: 0.0213 - val_acc: 0.9832\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0229 - acc: 0.9935 - val_loss: 0.0219 - val_acc: 0.9832\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0285 - acc: 0.9907 - val_loss: 0.0229 - val_acc: 0.9832\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0336 - acc: 0.9898 - val_loss: 0.0219 - val_acc: 0.9832\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0210 - acc: 0.9916 - val_loss: 0.0219 - val_acc: 0.9832\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 199us/step - loss: 0.0409 - acc: 0.9870 - val_loss: 0.0220 - val_acc: 0.9832\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0277 - acc: 0.9907 - val_loss: 0.0223 - val_acc: 0.9832\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0230 - acc: 0.9935 - val_loss: 0.0241 - val_acc: 0.9832\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 204us/step - loss: 0.0261 - acc: 0.9916 - val_loss: 0.0232 - val_acc: 0.9832\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0213 - acc: 0.9944 - val_loss: 0.0228 - val_acc: 0.9832\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0281 - acc: 0.9898 - val_loss: 0.0235 - val_acc: 0.9832\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0191 - acc: 0.9944 - val_loss: 0.0269 - val_acc: 0.9832\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0250 - acc: 0.9935 - val_loss: 0.0295 - val_acc: 0.9832\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0275 - acc: 0.9926 - val_loss: 0.0286 - val_acc: 0.9832\n",
      "\n",
      "Fold 4: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0365 - acc: 0.9879 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 204us/step - loss: 0.0244 - acc: 0.9926 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0172 - acc: 0.9954 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0209 - acc: 0.9963 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0201 - acc: 0.9944 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0255 - acc: 0.9935 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 190us/step - loss: 0.0308 - acc: 0.9916 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 189us/step - loss: 0.0246 - acc: 0.9907 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0179 - acc: 0.9972 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0252 - acc: 0.9916 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 191us/step - loss: 0.0207 - acc: 0.9935 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0178 - acc: 0.9935 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0148 - acc: 0.9954 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0143 - acc: 0.9944 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0135 - acc: 0.9963 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0230 - acc: 0.9944 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "\n",
      "Fold 5: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0204 - acc: 0.9926 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0193 - acc: 0.9954 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0193 - acc: 0.9935 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 198us/step - loss: 0.0180 - acc: 0.9935 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0150 - acc: 0.9944 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0202 - acc: 0.9963 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0161 - acc: 0.9954 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0153 - acc: 0.9963 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0199 - acc: 0.9935 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0152 - acc: 0.9963 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0213 - acc: 0.9916 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0139 - acc: 0.9963 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0219 - acc: 0.9935 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 204us/step - loss: 0.0162 - acc: 0.9944 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 201us/step - loss: 0.0102 - acc: 0.9972 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0157 - acc: 0.9944 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "\n",
      "Fold 6: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 205us/step - loss: 0.0146 - acc: 0.9963 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0116 - acc: 0.9981 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 201us/step - loss: 0.0152 - acc: 0.9954 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 199us/step - loss: 0.0123 - acc: 0.9963 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 5/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 0s 199us/step - loss: 0.0213 - acc: 0.9916 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 191us/step - loss: 0.0174 - acc: 0.9935 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 190us/step - loss: 0.0171 - acc: 0.9954 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 190us/step - loss: 0.0104 - acc: 0.9972 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 190us/step - loss: 0.0121 - acc: 0.9944 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 191us/step - loss: 0.0136 - acc: 0.9954 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 189us/step - loss: 0.0117 - acc: 0.9972 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0180 - acc: 0.9954 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0150 - acc: 0.9935 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 190us/step - loss: 0.0118 - acc: 0.9991 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0116 - acc: 0.9954 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "\n",
      "Fold 7: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 186us/step - loss: 0.0132 - acc: 0.9954 - val_loss: 7.0850e-04 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0106 - acc: 0.9981 - val_loss: 7.0249e-04 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 191us/step - loss: 0.0081 - acc: 0.9981 - val_loss: 6.2670e-04 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0146 - acc: 0.9954 - val_loss: 5.8319e-04 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 191us/step - loss: 0.0080 - acc: 0.9981 - val_loss: 5.9835e-04 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 5.7029e-04 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0079 - acc: 0.9991 - val_loss: 5.7413e-04 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 190us/step - loss: 0.0054 - acc: 0.9991 - val_loss: 5.3832e-04 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 191us/step - loss: 0.0097 - acc: 0.9963 - val_loss: 4.9862e-04 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0166 - acc: 0.9954 - val_loss: 4.7420e-04 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0098 - acc: 0.9954 - val_loss: 4.5114e-04 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0099 - acc: 0.9954 - val_loss: 4.3420e-04 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0151 - acc: 0.9926 - val_loss: 4.6059e-04 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 187us/step - loss: 0.0150 - acc: 0.9963 - val_loss: 4.8271e-04 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0088 - acc: 0.9981 - val_loss: 5.5623e-04 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0079 - acc: 0.9981 - val_loss: 5.1062e-04 - val_acc: 1.0000\n",
      "\n",
      "Fold 8: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0072 - acc: 0.9991 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0073 - acc: 0.9991 - val_loss: 9.5187e-04 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 198us/step - loss: 0.0103 - acc: 0.9954 - val_loss: 9.2326e-04 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 202us/step - loss: 0.0109 - acc: 0.9963 - val_loss: 9.6108e-04 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 200us/step - loss: 0.0245 - acc: 0.9926 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 198us/step - loss: 0.0093 - acc: 0.9963 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0089 - acc: 0.9972 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 201us/step - loss: 0.0116 - acc: 0.9972 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 200us/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 200us/step - loss: 0.0160 - acc: 0.9935 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0072 - acc: 0.9991 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0090 - acc: 0.9963 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0119 - acc: 0.9963 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0073 - acc: 0.9972 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "\n",
      "Fold 9: score=1.0\n",
      "Average AUC score: 0.9990698476573728\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores = []\n",
    "\n",
    "# sklearn.model_selection.KFold\n",
    "kf = StratifiedKFold(n_splits=10,\n",
    "          shuffle=True,\n",
    "          random_state=42069)\n",
    "\n",
    "for index_fold, (index_train, index_val) in enumerate(kf.split(x_train, y_train)):\n",
    "    x_train_f = x_train[index_train]\n",
    "    y_train_f = y_train[index_train]\n",
    "    \n",
    "    x_val_f = x_train[index_val]\n",
    "    y_val_f = y_train[index_val]\n",
    "    \n",
    "    # train\n",
    "    model.fit(x_train_f, y_train_f, batch_size=256, epochs=16, verbose=1, validation_data=(x_val_f, y_val_f))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # compute ROC-AUC score\n",
    "    pred_val = model.predict([x_val_f], batch_size=512)\n",
    "    \n",
    "    score_auc = sklearn.metrics.roc_auc_score(y_val_f, pred_val)\n",
    "    scores.append(score_auc)\n",
    "    \n",
    "    print('Fold {}: score={}'.format(index_fold, score_auc))\n",
    "    \n",
    "    \n",
    "print('Average AUC score: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model w/ Bidirectional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 10, 128)           512       \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 10, 256)           197376    \n",
      "_________________________________________________________________\n",
      "attention_4 (Attention)      (None, 256)               266       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 198,411\n",
      "Trainable params: 198,155\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# def get_model(input_dim, hidden_size=64, fc1_size=10, output_size=1, lr=1e-3):\n",
    "    \n",
    "#     # output shape = (None, seq_length, feature_size)\n",
    "#     inputs = keras.layers.Input(input_dim[1:])\n",
    "\n",
    "#     # output shape = (None, seq_length, hidden_size)\n",
    "#     x_rnn = keras.layers.GRU(units=hidden_size)(inputs)\n",
    "    \n",
    "#     # output shape = (None, fc1_size)\n",
    "#     x_attention = Attention(fc1_size)(x_rnn)\n",
    "    \n",
    "#     # output shape = (None, 1)\n",
    "#     outputs = keras.layers.Dense(output_size, activation='sigmoid')(x_attention)\n",
    "    \n",
    "#     model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "#     optimizer = keras.optimizers.Adam(lr=lr)\n",
    "    \n",
    "#     model.compile(loss='binary_crossentropy',\n",
    "#                   optimizer=optimizer,\n",
    "#                  metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(10, 128)))\n",
    "#     model.add(Bidirectional(RNN(64, activation='relu', return_sequences=True)))\n",
    "    model.add(Bidirectional(GRU(128, dropout=0.4, recurrent_dropout=0.4, activation='relu', return_sequences=True)))\n",
    "    model.add(Attention(10))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "input_dim = x_train.shape\n",
    "# model = get_model(input_dim)\n",
    "model = get_model()\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-Fold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1074 samples, validate on 121 samples\n",
      "Epoch 1/16\n",
      "1074/1074 [==============================] - 2s 2ms/step - loss: 0.6147 - acc: 0.6620 - val_loss: 0.3460 - val_acc: 0.9174\n",
      "Epoch 2/16\n",
      "1074/1074 [==============================] - 0s 389us/step - loss: 0.3145 - acc: 0.9134 - val_loss: 0.2029 - val_acc: 0.9421\n",
      "Epoch 3/16\n",
      "1074/1074 [==============================] - 0s 390us/step - loss: 0.2053 - acc: 0.9348 - val_loss: 0.1550 - val_acc: 0.9504\n",
      "Epoch 4/16\n",
      "1074/1074 [==============================] - 0s 399us/step - loss: 0.1614 - acc: 0.9348 - val_loss: 0.1430 - val_acc: 0.9587\n",
      "Epoch 5/16\n",
      "1074/1074 [==============================] - 0s 392us/step - loss: 0.1442 - acc: 0.9432 - val_loss: 0.1412 - val_acc: 0.9587\n",
      "Epoch 6/16\n",
      "1074/1074 [==============================] - 0s 403us/step - loss: 0.1415 - acc: 0.9451 - val_loss: 0.1386 - val_acc: 0.9587\n",
      "Epoch 7/16\n",
      "1074/1074 [==============================] - 0s 380us/step - loss: 0.1215 - acc: 0.9544 - val_loss: 0.1363 - val_acc: 0.9587\n",
      "Epoch 8/16\n",
      "1074/1074 [==============================] - 0s 389us/step - loss: 0.1232 - acc: 0.9488 - val_loss: 0.1336 - val_acc: 0.9587\n",
      "Epoch 9/16\n",
      "1074/1074 [==============================] - 0s 398us/step - loss: 0.1137 - acc: 0.9572 - val_loss: 0.1327 - val_acc: 0.9504\n",
      "Epoch 10/16\n",
      "1074/1074 [==============================] - 0s 386us/step - loss: 0.1077 - acc: 0.9618 - val_loss: 0.1303 - val_acc: 0.9504\n",
      "Epoch 11/16\n",
      "1074/1074 [==============================] - 0s 398us/step - loss: 0.1005 - acc: 0.9637 - val_loss: 0.1286 - val_acc: 0.9504\n",
      "Epoch 12/16\n",
      "1074/1074 [==============================] - 0s 395us/step - loss: 0.0983 - acc: 0.9590 - val_loss: 0.1281 - val_acc: 0.9504\n",
      "Epoch 13/16\n",
      "1074/1074 [==============================] - 0s 387us/step - loss: 0.0990 - acc: 0.9665 - val_loss: 0.1296 - val_acc: 0.9504\n",
      "Epoch 14/16\n",
      "1074/1074 [==============================] - 0s 390us/step - loss: 0.0881 - acc: 0.9655 - val_loss: 0.1320 - val_acc: 0.9504\n",
      "Epoch 15/16\n",
      "1074/1074 [==============================] - 0s 382us/step - loss: 0.0919 - acc: 0.9702 - val_loss: 0.1329 - val_acc: 0.9504\n",
      "Epoch 16/16\n",
      "1074/1074 [==============================] - 0s 389us/step - loss: 0.0869 - acc: 0.9683 - val_loss: 0.1329 - val_acc: 0.9504\n",
      "\n",
      "Fold 0: score=0.9901408450704225\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/16\n",
      "1075/1075 [==============================] - 0s 387us/step - loss: 0.0918 - acc: 0.9609 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1075/1075 [==============================] - 0s 407us/step - loss: 0.0977 - acc: 0.9647 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1075/1075 [==============================] - 0s 384us/step - loss: 0.0961 - acc: 0.9656 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1075/1075 [==============================] - 0s 401us/step - loss: 0.0841 - acc: 0.9684 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1075/1075 [==============================] - 0s 394us/step - loss: 0.0899 - acc: 0.9702 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1075/1075 [==============================] - 0s 389us/step - loss: 0.0762 - acc: 0.9721 - val_loss: 0.0211 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1075/1075 [==============================] - 0s 405us/step - loss: 0.0808 - acc: 0.9656 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1075/1075 [==============================] - 0s 392us/step - loss: 0.0771 - acc: 0.9730 - val_loss: 0.0202 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1075/1075 [==============================] - 0s 390us/step - loss: 0.0770 - acc: 0.9693 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1075/1075 [==============================] - 0s 392us/step - loss: 0.0722 - acc: 0.9749 - val_loss: 0.0221 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1075/1075 [==============================] - 0s 388us/step - loss: 0.0774 - acc: 0.9730 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1075/1075 [==============================] - 0s 392us/step - loss: 0.0693 - acc: 0.9740 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1075/1075 [==============================] - 0s 399us/step - loss: 0.0632 - acc: 0.9814 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1075/1075 [==============================] - 0s 394us/step - loss: 0.0622 - acc: 0.9833 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1075/1075 [==============================] - 0s 396us/step - loss: 0.0609 - acc: 0.9786 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1075/1075 [==============================] - 0s 388us/step - loss: 0.0681 - acc: 0.9777 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "\n",
      "Fold 1: score=1.0\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/16\n",
      "1075/1075 [==============================] - 0s 391us/step - loss: 0.0538 - acc: 0.9814 - val_loss: 0.0314 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1075/1075 [==============================] - 0s 404us/step - loss: 0.0629 - acc: 0.9758 - val_loss: 0.0269 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1075/1075 [==============================] - 0s 397us/step - loss: 0.0547 - acc: 0.9805 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1075/1075 [==============================] - 0s 393us/step - loss: 0.0453 - acc: 0.9888 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1075/1075 [==============================] - 0s 391us/step - loss: 0.0491 - acc: 0.9833 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1075/1075 [==============================] - 0s 395us/step - loss: 0.0507 - acc: 0.9823 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1075/1075 [==============================] - 0s 393us/step - loss: 0.0411 - acc: 0.9860 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1075/1075 [==============================] - 0s 390us/step - loss: 0.0415 - acc: 0.9898 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1075/1075 [==============================] - 0s 395us/step - loss: 0.0445 - acc: 0.9870 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1075/1075 [==============================] - 0s 387us/step - loss: 0.0495 - acc: 0.9842 - val_loss: 0.0374 - val_acc: 0.9833\n",
      "Epoch 11/16\n",
      "1075/1075 [==============================] - 0s 386us/step - loss: 0.0459 - acc: 0.9795 - val_loss: 0.0421 - val_acc: 0.9833\n",
      "Epoch 12/16\n",
      "1075/1075 [==============================] - 0s 391us/step - loss: 0.0386 - acc: 0.9851 - val_loss: 0.0525 - val_acc: 0.9833\n",
      "Epoch 13/16\n",
      "1075/1075 [==============================] - 0s 393us/step - loss: 0.0355 - acc: 0.9898 - val_loss: 0.0411 - val_acc: 0.9833\n",
      "Epoch 14/16\n",
      "1075/1075 [==============================] - 0s 399us/step - loss: 0.0359 - acc: 0.9870 - val_loss: 0.0270 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1075/1075 [==============================] - 0s 390us/step - loss: 0.0329 - acc: 0.9870 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1075/1075 [==============================] - 0s 389us/step - loss: 0.0327 - acc: 0.9916 - val_loss: 0.0267 - val_acc: 1.0000\n",
      "\n",
      "Fold 2: score=1.0\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/16\n",
      "1075/1075 [==============================] - 0s 389us/step - loss: 0.0284 - acc: 0.9888 - val_loss: 0.0179 - val_acc: 0.9917\n",
      "Epoch 2/16\n",
      "1075/1075 [==============================] - 0s 401us/step - loss: 0.0312 - acc: 0.9888 - val_loss: 0.0179 - val_acc: 0.9917\n",
      "Epoch 3/16\n",
      "1075/1075 [==============================] - 0s 394us/step - loss: 0.0335 - acc: 0.9870 - val_loss: 0.0159 - val_acc: 0.9917\n",
      "Epoch 4/16\n",
      "1075/1075 [==============================] - 0s 394us/step - loss: 0.0329 - acc: 0.9870 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1075/1075 [==============================] - 0s 401us/step - loss: 0.0387 - acc: 0.9860 - val_loss: 0.0167 - val_acc: 0.9917\n",
      "Epoch 6/16\n",
      "1075/1075 [==============================] - 0s 387us/step - loss: 0.0229 - acc: 0.9907 - val_loss: 0.0202 - val_acc: 0.9917\n",
      "Epoch 7/16\n",
      "1075/1075 [==============================] - 0s 412us/step - loss: 0.0237 - acc: 0.9926 - val_loss: 0.0210 - val_acc: 0.9917\n",
      "Epoch 8/16\n",
      "1075/1075 [==============================] - 0s 393us/step - loss: 0.0233 - acc: 0.9907 - val_loss: 0.0196 - val_acc: 0.9917\n",
      "Epoch 9/16\n",
      "1075/1075 [==============================] - 0s 396us/step - loss: 0.0184 - acc: 0.9963 - val_loss: 0.0186 - val_acc: 0.9917\n",
      "Epoch 10/16\n",
      "1075/1075 [==============================] - 0s 406us/step - loss: 0.0247 - acc: 0.9907 - val_loss: 0.0216 - val_acc: 0.9917\n",
      "Epoch 11/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075/1075 [==============================] - 0s 392us/step - loss: 0.0266 - acc: 0.9926 - val_loss: 0.0280 - val_acc: 0.9917\n",
      "Epoch 12/16\n",
      "1075/1075 [==============================] - 0s 397us/step - loss: 0.0259 - acc: 0.9907 - val_loss: 0.0318 - val_acc: 0.9917\n",
      "Epoch 13/16\n",
      "1075/1075 [==============================] - 0s 402us/step - loss: 0.0257 - acc: 0.9916 - val_loss: 0.0320 - val_acc: 0.9917\n",
      "Epoch 14/16\n",
      "1075/1075 [==============================] - 0s 387us/step - loss: 0.0204 - acc: 0.9926 - val_loss: 0.0294 - val_acc: 0.9917\n",
      "Epoch 15/16\n",
      "1075/1075 [==============================] - 0s 398us/step - loss: 0.0176 - acc: 0.9953 - val_loss: 0.0299 - val_acc: 0.9917\n",
      "Epoch 16/16\n",
      "1075/1075 [==============================] - 0s 397us/step - loss: 0.0223 - acc: 0.9935 - val_loss: 0.0320 - val_acc: 0.9917\n",
      "\n",
      "Fold 3: score=0.9994251221615407\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 390us/step - loss: 0.0180 - acc: 0.9963 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 400us/step - loss: 0.0171 - acc: 0.9935 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 385us/step - loss: 0.0199 - acc: 0.9935 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 396us/step - loss: 0.0228 - acc: 0.9935 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 385us/step - loss: 0.0163 - acc: 0.9963 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 388us/step - loss: 0.0196 - acc: 0.9926 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 394us/step - loss: 0.0135 - acc: 0.9972 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0195 - acc: 0.9954 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 395us/step - loss: 0.0205 - acc: 0.9944 - val_loss: 0.0182 - val_acc: 0.9916\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 406us/step - loss: 0.0232 - acc: 0.9926 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 390us/step - loss: 0.0122 - acc: 0.9972 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 399us/step - loss: 0.0133 - acc: 0.9972 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 401us/step - loss: 0.0161 - acc: 0.9954 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 399us/step - loss: 0.0095 - acc: 0.9981 - val_loss: 0.0183 - val_acc: 0.9916\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 397us/step - loss: 0.0190 - acc: 0.9935 - val_loss: 0.0192 - val_acc: 0.9916\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 391us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "\n",
      "Fold 4: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 390us/step - loss: 0.0151 - acc: 0.9954 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 390us/step - loss: 0.0145 - acc: 0.9954 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 391us/step - loss: 0.0166 - acc: 0.9944 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 394us/step - loss: 0.0142 - acc: 0.9935 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 388us/step - loss: 0.0106 - acc: 0.9972 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0140 - acc: 0.9954 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 386us/step - loss: 0.0107 - acc: 0.9972 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 401us/step - loss: 0.0107 - acc: 0.9963 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 400us/step - loss: 0.0104 - acc: 0.9954 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 385us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 398us/step - loss: 0.0145 - acc: 0.9972 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 396us/step - loss: 0.0077 - acc: 0.9981 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0143 - acc: 0.9944 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 383us/step - loss: 0.0119 - acc: 0.9972 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 392us/step - loss: 0.0116 - acc: 0.9981 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "\n",
      "Fold 5: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 394us/step - loss: 0.0133 - acc: 0.9944 - val_loss: 6.1188e-04 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 399us/step - loss: 0.0179 - acc: 0.9935 - val_loss: 5.2636e-04 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 400us/step - loss: 0.0059 - acc: 0.9981 - val_loss: 5.4015e-04 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 392us/step - loss: 0.0104 - acc: 0.9963 - val_loss: 5.5303e-04 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 399us/step - loss: 0.0083 - acc: 0.9981 - val_loss: 6.5389e-04 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 385us/step - loss: 0.0107 - acc: 0.9963 - val_loss: 9.8992e-04 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 386us/step - loss: 0.0084 - acc: 0.9991 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 403us/step - loss: 0.0124 - acc: 0.9972 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0099 - acc: 0.9972 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0079 - acc: 0.9981 - val_loss: 9.0359e-04 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 394us/step - loss: 0.0050 - acc: 0.9991 - val_loss: 9.4219e-04 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0077 - acc: 0.9972 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 392us/step - loss: 0.0132 - acc: 0.9963 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 397us/step - loss: 0.0114 - acc: 0.9954 - val_loss: 9.0373e-04 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 392us/step - loss: 0.0071 - acc: 0.9981 - val_loss: 7.8728e-04 - val_acc: 1.0000\n",
      "\n",
      "Fold 6: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 383us/step - loss: 0.0157 - acc: 0.9944 - val_loss: 4.5784e-04 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 401us/step - loss: 0.0079 - acc: 0.9981 - val_loss: 4.8132e-04 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0089 - acc: 0.9981 - val_loss: 5.6570e-04 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 407us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 4.7290e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 396us/step - loss: 0.0091 - acc: 0.9972 - val_loss: 4.8713e-04 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 390us/step - loss: 0.0086 - acc: 0.9981 - val_loss: 6.1685e-04 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0066 - acc: 0.9981 - val_loss: 6.2527e-04 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 385us/step - loss: 0.0055 - acc: 0.9981 - val_loss: 6.0206e-04 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 405us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 5.5121e-04 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 400us/step - loss: 0.0077 - acc: 0.9981 - val_loss: 4.5831e-04 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 390us/step - loss: 0.0081 - acc: 0.9972 - val_loss: 4.7899e-04 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 382us/step - loss: 0.0060 - acc: 0.9981 - val_loss: 5.0898e-04 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 388us/step - loss: 0.0043 - acc: 0.9991 - val_loss: 5.0808e-04 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 394us/step - loss: 0.0056 - acc: 0.9991 - val_loss: 4.5991e-04 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 401us/step - loss: 0.0055 - acc: 0.9991 - val_loss: 4.8356e-04 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 391us/step - loss: 0.0078 - acc: 0.9981 - val_loss: 4.2587e-04 - val_acc: 1.0000\n",
      "\n",
      "Fold 7: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0071 - acc: 0.9963 - val_loss: 2.3543e-04 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 388us/step - loss: 0.0055 - acc: 0.9981 - val_loss: 2.3666e-04 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0133 - acc: 0.9954 - val_loss: 2.6121e-04 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 399us/step - loss: 0.0046 - acc: 0.9981 - val_loss: 3.0797e-04 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 391us/step - loss: 0.0056 - acc: 0.9981 - val_loss: 3.4727e-04 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0089 - acc: 0.9972 - val_loss: 3.9782e-04 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 384us/step - loss: 0.0042 - acc: 0.9991 - val_loss: 4.2898e-04 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0047 - acc: 0.9981 - val_loss: 4.5674e-04 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 384us/step - loss: 0.0070 - acc: 0.9991 - val_loss: 4.5807e-04 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 402us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 4.2641e-04 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0052 - acc: 0.9991 - val_loss: 4.0796e-04 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 399us/step - loss: 0.0048 - acc: 0.9981 - val_loss: 3.7279e-04 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 3.5316e-04 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 396us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 3.8765e-04 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 396us/step - loss: 0.0105 - acc: 0.9954 - val_loss: 4.0765e-04 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 392us/step - loss: 0.0040 - acc: 0.9981 - val_loss: 5.0187e-04 - val_acc: 1.0000\n",
      "\n",
      "Fold 8: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0072 - acc: 0.9972 - val_loss: 4.7891e-04 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0087 - acc: 0.9972 - val_loss: 6.4289e-04 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 386us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.1479e-04 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 2.9416e-04 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 385us/step - loss: 0.0056 - acc: 0.9981 - val_loss: 3.1558e-04 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 386us/step - loss: 0.0039 - acc: 0.9991 - val_loss: 3.7565e-04 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 386us/step - loss: 0.0048 - acc: 0.9991 - val_loss: 3.0427e-04 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 382us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 2.2648e-04 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 386us/step - loss: 0.0078 - acc: 0.9991 - val_loss: 2.1346e-04 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 404us/step - loss: 0.0064 - acc: 0.9991 - val_loss: 2.6601e-04 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 382us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 4.7392e-04 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 384us/step - loss: 0.0070 - acc: 0.9981 - val_loss: 5.4889e-04 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 383us/step - loss: 0.0047 - acc: 0.9991 - val_loss: 5.1863e-04 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0042 - acc: 0.9981 - val_loss: 4.6093e-04 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 3.5573e-04 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 402us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.8749e-04 - val_acc: 1.0000\n",
      "\n",
      "Fold 9: score=1.0\n",
      "Average AUC score: 0.9989565967231963\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores = []\n",
    "\n",
    "# sklearn.model_selection.KFold\n",
    "kf = StratifiedKFold(n_splits=10,\n",
    "          shuffle=True,\n",
    "          random_state=42069)\n",
    "\n",
    "for index_fold, (index_train, index_val) in enumerate(kf.split(x_train, y_train)):\n",
    "    x_train_f = x_train[index_train]\n",
    "    y_train_f = y_train[index_train]\n",
    "    \n",
    "    x_val_f = x_train[index_val]\n",
    "    y_val_f = y_train[index_val]\n",
    "    \n",
    "    # train\n",
    "    model.fit(x_train_f, y_train_f, batch_size=256, epochs=16, verbose=1, validation_data=(x_val_f, y_val_f))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # compute ROC-AUC score\n",
    "    pred_val = model.predict([x_val_f], batch_size=512)\n",
    "    \n",
    "    score_auc = sklearn.metrics.roc_auc_score(y_val_f, pred_val)\n",
    "    scores.append(score_auc)\n",
    "    \n",
    "    print('Fold {}: score={}'.format(index_fold, score_auc))\n",
    "    \n",
    "    \n",
    "print('Average AUC score: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model w/o Attention, but w/ GlobalAveragePooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 10, 128)           512       \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 10, 128)           98688     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 99,329\n",
      "Trainable params: 99,073\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(10, 128)))\n",
    "#     model.add(Bidirectional(RNN(64, activation='relu', return_sequences=True)))\n",
    "#     model.add(Bidirectional(GRU(128, dropout=0.4, recurrent_dropout=0.4, activation='relu', return_sequences=True)))\n",
    "    model.add(GRU(128, dropout=0.4, recurrent_dropout=0.4, activation='relu', return_sequences=True))\n",
    "#     model.add(Attention(10))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "input_dim = x_train.shape\n",
    "# model = get_model(input_dim)\n",
    "model = get_model()\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1074 samples, validate on 121 samples\n",
      "Epoch 1/16\n",
      "1074/1074 [==============================] - 1s 1ms/step - loss: 0.6525 - acc: 0.5931 - val_loss: 0.4091 - val_acc: 0.9256\n",
      "Epoch 2/16\n",
      "1074/1074 [==============================] - 0s 195us/step - loss: 0.3791 - acc: 0.8985 - val_loss: 0.2443 - val_acc: 0.9587\n",
      "Epoch 3/16\n",
      "1074/1074 [==============================] - 0s 199us/step - loss: 0.2548 - acc: 0.9181 - val_loss: 0.1729 - val_acc: 0.9587\n",
      "Epoch 4/16\n",
      "1074/1074 [==============================] - 0s 189us/step - loss: 0.2055 - acc: 0.9171 - val_loss: 0.1432 - val_acc: 0.9587\n",
      "Epoch 5/16\n",
      "1074/1074 [==============================] - 0s 190us/step - loss: 0.1639 - acc: 0.9376 - val_loss: 0.1314 - val_acc: 0.9669\n",
      "Epoch 6/16\n",
      "1074/1074 [==============================] - 0s 194us/step - loss: 0.1682 - acc: 0.9376 - val_loss: 0.1281 - val_acc: 0.9669\n",
      "Epoch 7/16\n",
      "1074/1074 [==============================] - 0s 188us/step - loss: 0.1503 - acc: 0.9432 - val_loss: 0.1256 - val_acc: 0.9587\n",
      "Epoch 8/16\n",
      "1074/1074 [==============================] - 0s 189us/step - loss: 0.1524 - acc: 0.9395 - val_loss: 0.1238 - val_acc: 0.9587\n",
      "Epoch 9/16\n",
      "1074/1074 [==============================] - 0s 190us/step - loss: 0.1464 - acc: 0.9413 - val_loss: 0.1232 - val_acc: 0.9587\n",
      "Epoch 10/16\n",
      "1074/1074 [==============================] - 0s 192us/step - loss: 0.1459 - acc: 0.9404 - val_loss: 0.1237 - val_acc: 0.9669\n",
      "Epoch 11/16\n",
      "1074/1074 [==============================] - 0s 188us/step - loss: 0.1284 - acc: 0.9460 - val_loss: 0.1217 - val_acc: 0.9587\n",
      "Epoch 12/16\n",
      "1074/1074 [==============================] - 0s 187us/step - loss: 0.1360 - acc: 0.9441 - val_loss: 0.1200 - val_acc: 0.9587\n",
      "Epoch 13/16\n",
      "1074/1074 [==============================] - 0s 185us/step - loss: 0.1217 - acc: 0.9479 - val_loss: 0.1182 - val_acc: 0.9587\n",
      "Epoch 14/16\n",
      "1074/1074 [==============================] - 0s 190us/step - loss: 0.1260 - acc: 0.9553 - val_loss: 0.1170 - val_acc: 0.9587\n",
      "Epoch 15/16\n",
      "1074/1074 [==============================] - 0s 188us/step - loss: 0.1125 - acc: 0.9553 - val_loss: 0.1155 - val_acc: 0.9587\n",
      "Epoch 16/16\n",
      "1074/1074 [==============================] - 0s 193us/step - loss: 0.1162 - acc: 0.9525 - val_loss: 0.1152 - val_acc: 0.9587\n",
      "\n",
      "Fold 0: score=0.9907042253521127\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/16\n",
      "1075/1075 [==============================] - 0s 187us/step - loss: 0.1124 - acc: 0.9572 - val_loss: 0.0329 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1075/1075 [==============================] - 0s 191us/step - loss: 0.1206 - acc: 0.9479 - val_loss: 0.0328 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1075/1075 [==============================] - 0s 185us/step - loss: 0.1304 - acc: 0.9572 - val_loss: 0.0366 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1075/1075 [==============================] - 0s 188us/step - loss: 0.1052 - acc: 0.9600 - val_loss: 0.0374 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1075/1075 [==============================] - 0s 187us/step - loss: 0.1207 - acc: 0.9516 - val_loss: 0.0345 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1075/1075 [==============================] - 0s 194us/step - loss: 0.1082 - acc: 0.9647 - val_loss: 0.0330 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1075/1075 [==============================] - 0s 188us/step - loss: 0.1169 - acc: 0.9516 - val_loss: 0.0318 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1075/1075 [==============================] - 0s 190us/step - loss: 0.1111 - acc: 0.9535 - val_loss: 0.0319 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1075/1075 [==============================] - 0s 193us/step - loss: 0.0978 - acc: 0.9619 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1075/1075 [==============================] - 0s 187us/step - loss: 0.1051 - acc: 0.9591 - val_loss: 0.0313 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1075/1075 [==============================] - 0s 187us/step - loss: 0.0983 - acc: 0.9628 - val_loss: 0.0306 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1075/1075 [==============================] - 0s 190us/step - loss: 0.0961 - acc: 0.9665 - val_loss: 0.0311 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1075/1075 [==============================] - 0s 194us/step - loss: 0.0903 - acc: 0.9665 - val_loss: 0.0307 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1075/1075 [==============================] - 0s 187us/step - loss: 0.1024 - acc: 0.9553 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1075/1075 [==============================] - 0s 188us/step - loss: 0.0831 - acc: 0.9665 - val_loss: 0.0297 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 0.0951 - acc: 0.9619 - val_loss: 0.0285 - val_acc: 1.0000\n",
      "\n",
      "Fold 1: score=1.0\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/16\n",
      "1075/1075 [==============================] - 0s 190us/step - loss: 0.0896 - acc: 0.9702 - val_loss: 0.0439 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1075/1075 [==============================] - 0s 193us/step - loss: 0.0756 - acc: 0.9702 - val_loss: 0.0431 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1075/1075 [==============================] - 0s 188us/step - loss: 0.0862 - acc: 0.9712 - val_loss: 0.0445 - val_acc: 0.9917\n",
      "Epoch 4/16\n",
      "1075/1075 [==============================] - 0s 188us/step - loss: 0.0754 - acc: 0.9721 - val_loss: 0.0445 - val_acc: 0.9917\n",
      "Epoch 5/16\n",
      "1075/1075 [==============================] - 0s 189us/step - loss: 0.0703 - acc: 0.9749 - val_loss: 0.0440 - val_acc: 0.9917\n",
      "Epoch 6/16\n",
      "1075/1075 [==============================] - 0s 187us/step - loss: 0.0853 - acc: 0.9684 - val_loss: 0.0441 - val_acc: 0.9917\n",
      "Epoch 7/16\n",
      "1075/1075 [==============================] - 0s 185us/step - loss: 0.0881 - acc: 0.9665 - val_loss: 0.0459 - val_acc: 0.9917\n",
      "Epoch 8/16\n",
      "1075/1075 [==============================] - 0s 190us/step - loss: 0.0760 - acc: 0.9758 - val_loss: 0.0602 - val_acc: 0.9833\n",
      "Epoch 9/16\n",
      "1075/1075 [==============================] - 0s 190us/step - loss: 0.0743 - acc: 0.9693 - val_loss: 0.0562 - val_acc: 0.9917\n",
      "Epoch 10/16\n",
      "1075/1075 [==============================] - 0s 187us/step - loss: 0.0734 - acc: 0.9795 - val_loss: 0.0403 - val_acc: 0.9917\n",
      "Epoch 11/16\n",
      "1075/1075 [==============================] - 0s 192us/step - loss: 0.0768 - acc: 0.9749 - val_loss: 0.0391 - val_acc: 0.9917\n",
      "Epoch 12/16\n",
      "1075/1075 [==============================] - 0s 193us/step - loss: 0.0757 - acc: 0.9758 - val_loss: 0.0564 - val_acc: 0.9833\n",
      "Epoch 13/16\n",
      "1075/1075 [==============================] - 0s 191us/step - loss: 0.0656 - acc: 0.9740 - val_loss: 0.0541 - val_acc: 0.9917\n",
      "Epoch 14/16\n",
      "1075/1075 [==============================] - 0s 189us/step - loss: 0.0706 - acc: 0.9749 - val_loss: 0.0600 - val_acc: 0.9917\n",
      "Epoch 15/16\n",
      "1075/1075 [==============================] - 0s 197us/step - loss: 0.0598 - acc: 0.9767 - val_loss: 0.0545 - val_acc: 0.9917\n",
      "Epoch 16/16\n",
      "1075/1075 [==============================] - 0s 240us/step - loss: 0.0574 - acc: 0.9805 - val_loss: 0.0411 - val_acc: 0.9917\n",
      "\n",
      "Fold 2: score=1.0\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/16\n",
      "1075/1075 [==============================] - 0s 195us/step - loss: 0.0617 - acc: 0.9777 - val_loss: 0.0458 - val_acc: 0.9833\n",
      "Epoch 2/16\n",
      "1075/1075 [==============================] - 0s 197us/step - loss: 0.0666 - acc: 0.9730 - val_loss: 0.0464 - val_acc: 0.9833\n",
      "Epoch 3/16\n",
      "1075/1075 [==============================] - 0s 193us/step - loss: 0.0527 - acc: 0.9814 - val_loss: 0.0476 - val_acc: 0.9833\n",
      "Epoch 4/16\n",
      "1075/1075 [==============================] - 0s 192us/step - loss: 0.0588 - acc: 0.9767 - val_loss: 0.0445 - val_acc: 0.9833\n",
      "Epoch 5/16\n",
      "1075/1075 [==============================] - 0s 193us/step - loss: 0.0487 - acc: 0.9814 - val_loss: 0.0434 - val_acc: 0.9833\n",
      "Epoch 6/16\n",
      "1075/1075 [==============================] - 0s 193us/step - loss: 0.0737 - acc: 0.9740 - val_loss: 0.0458 - val_acc: 0.9833\n",
      "Epoch 7/16\n",
      "1075/1075 [==============================] - 0s 195us/step - loss: 0.0540 - acc: 0.9786 - val_loss: 0.0609 - val_acc: 0.9750\n",
      "Epoch 8/16\n",
      "1075/1075 [==============================] - 0s 193us/step - loss: 0.0642 - acc: 0.9786 - val_loss: 0.0623 - val_acc: 0.9750\n",
      "Epoch 9/16\n",
      "1075/1075 [==============================] - 0s 194us/step - loss: 0.0512 - acc: 0.9795 - val_loss: 0.0520 - val_acc: 0.9833\n",
      "Epoch 10/16\n",
      "1075/1075 [==============================] - 0s 197us/step - loss: 0.0510 - acc: 0.9777 - val_loss: 0.0494 - val_acc: 0.9833\n",
      "Epoch 11/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075/1075 [==============================] - 0s 199us/step - loss: 0.0628 - acc: 0.9758 - val_loss: 0.0494 - val_acc: 0.9833\n",
      "Epoch 12/16\n",
      "1075/1075 [==============================] - 0s 216us/step - loss: 0.0476 - acc: 0.9814 - val_loss: 0.0505 - val_acc: 0.9833\n",
      "Epoch 13/16\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 0.0472 - acc: 0.9870 - val_loss: 0.0514 - val_acc: 0.9833\n",
      "Epoch 14/16\n",
      "1075/1075 [==============================] - 0s 203us/step - loss: 0.0480 - acc: 0.9767 - val_loss: 0.0493 - val_acc: 0.9833\n",
      "Epoch 15/16\n",
      "1075/1075 [==============================] - 0s 198us/step - loss: 0.0447 - acc: 0.9805 - val_loss: 0.0496 - val_acc: 0.9833\n",
      "Epoch 16/16\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 0.0420 - acc: 0.9870 - val_loss: 0.0520 - val_acc: 0.9833\n",
      "\n",
      "Fold 3: score=0.999137683242311\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0494 - acc: 0.9823 - val_loss: 0.0297 - val_acc: 0.9832\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0361 - acc: 0.9861 - val_loss: 0.0302 - val_acc: 0.9832\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0455 - acc: 0.9851 - val_loss: 0.0308 - val_acc: 0.9832\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0523 - acc: 0.9796 - val_loss: 0.0302 - val_acc: 0.9832\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0427 - acc: 0.9879 - val_loss: 0.0314 - val_acc: 0.9832\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0392 - acc: 0.9870 - val_loss: 0.0330 - val_acc: 0.9832\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0383 - acc: 0.9861 - val_loss: 0.0331 - val_acc: 0.9832\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0434 - acc: 0.9842 - val_loss: 0.0371 - val_acc: 0.9832\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0446 - acc: 0.9796 - val_loss: 0.0383 - val_acc: 0.9832\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 202us/step - loss: 0.0424 - acc: 0.9823 - val_loss: 0.0349 - val_acc: 0.9832\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0328 - acc: 0.9879 - val_loss: 0.0378 - val_acc: 0.9832\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0382 - acc: 0.9888 - val_loss: 0.0427 - val_acc: 0.9748\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0315 - acc: 0.9907 - val_loss: 0.0452 - val_acc: 0.9748\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 198us/step - loss: 0.0279 - acc: 0.9907 - val_loss: 0.0459 - val_acc: 0.9748\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0386 - acc: 0.9907 - val_loss: 0.0408 - val_acc: 0.9748\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0268 - acc: 0.9907 - val_loss: 0.0366 - val_acc: 0.9832\n",
      "\n",
      "Fold 4: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 188us/step - loss: 0.0367 - acc: 0.9870 - val_loss: 0.0151 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0295 - acc: 0.9907 - val_loss: 0.0139 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0271 - acc: 0.9916 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0415 - acc: 0.9861 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0339 - acc: 0.9879 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 190us/step - loss: 0.0296 - acc: 0.9879 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0345 - acc: 0.9879 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0320 - acc: 0.9879 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0269 - acc: 0.9916 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0256 - acc: 0.9916 - val_loss: 0.0207 - val_acc: 0.9916\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0255 - acc: 0.9888 - val_loss: 0.0256 - val_acc: 0.9832\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0232 - acc: 0.9926 - val_loss: 0.0265 - val_acc: 0.9832\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0286 - acc: 0.9898 - val_loss: 0.0256 - val_acc: 0.9832\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 190us/step - loss: 0.0316 - acc: 0.9870 - val_loss: 0.0236 - val_acc: 0.9832\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 191us/step - loss: 0.0179 - acc: 0.9954 - val_loss: 0.0233 - val_acc: 0.9916\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 199us/step - loss: 0.0218 - acc: 0.9954 - val_loss: 0.0220 - val_acc: 0.9916\n",
      "\n",
      "Fold 5: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0318 - acc: 0.9888 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0336 - acc: 0.9851 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 198us/step - loss: 0.0184 - acc: 0.9954 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 191us/step - loss: 0.0274 - acc: 0.9916 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0239 - acc: 0.9926 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 198us/step - loss: 0.0321 - acc: 0.9907 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0340 - acc: 0.9907 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0209 - acc: 0.9935 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 198us/step - loss: 0.0206 - acc: 0.9954 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 198us/step - loss: 0.0183 - acc: 0.9972 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0243 - acc: 0.9916 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0195 - acc: 0.9972 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0195 - acc: 0.9944 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0162 - acc: 0.9963 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0176 - acc: 0.9944 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0205 - acc: 0.9944 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "\n",
      "Fold 6: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0140 - acc: 0.9972 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0140 - acc: 0.9944 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 198us/step - loss: 0.0197 - acc: 0.9916 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 200us/step - loss: 0.0186 - acc: 0.9963 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 5/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 0s 200us/step - loss: 0.0241 - acc: 0.9916 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0172 - acc: 0.9954 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 201us/step - loss: 0.0214 - acc: 0.9954 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 198us/step - loss: 0.0189 - acc: 0.9926 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0190 - acc: 0.9963 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0171 - acc: 0.9963 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0200 - acc: 0.9916 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0205 - acc: 0.9935 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 188us/step - loss: 0.0189 - acc: 0.9935 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0284 - acc: 0.9916 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0211 - acc: 0.9954 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0223 - acc: 0.9916 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "\n",
      "Fold 7: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0174 - acc: 0.9963 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0145 - acc: 0.9972 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 198us/step - loss: 0.0195 - acc: 0.9954 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 195us/step - loss: 0.0227 - acc: 0.9888 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 191us/step - loss: 0.0163 - acc: 0.9944 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0148 - acc: 0.9972 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 191us/step - loss: 0.0139 - acc: 0.9981 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0135 - acc: 0.9954 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0103 - acc: 0.9981 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 196us/step - loss: 0.0169 - acc: 0.9944 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0200 - acc: 0.9916 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0143 - acc: 0.9954 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0133 - acc: 0.9981 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0119 - acc: 0.9991 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0152 - acc: 0.9944 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0140 - acc: 0.9954 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "\n",
      "Fold 8: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 193us/step - loss: 0.0094 - acc: 0.9972 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0196 - acc: 0.9926 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0101 - acc: 0.9981 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 197us/step - loss: 0.0122 - acc: 0.9972 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0119 - acc: 0.9972 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0150 - acc: 0.9954 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 198us/step - loss: 0.0077 - acc: 0.9991 - val_loss: 0.0071 - val_acc: 0.9916\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 191us/step - loss: 0.0081 - acc: 0.9972 - val_loss: 0.0074 - val_acc: 0.9916\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 190us/step - loss: 0.0089 - acc: 0.9981 - val_loss: 0.0069 - val_acc: 0.9916\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 191us/step - loss: 0.0078 - acc: 0.9963 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 186us/step - loss: 0.0073 - acc: 0.9972 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 192us/step - loss: 0.0167 - acc: 0.9944 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 189us/step - loss: 0.0140 - acc: 0.9944 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 189us/step - loss: 0.0085 - acc: 0.9972 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 194us/step - loss: 0.0110 - acc: 0.9944 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 189us/step - loss: 0.0054 - acc: 0.9981 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "\n",
      "Fold 9: score=1.0\n",
      "Average AUC score: 0.9989841908594423\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores = []\n",
    "\n",
    "# sklearn.model_selection.KFold\n",
    "kf = StratifiedKFold(n_splits=10,\n",
    "          shuffle=True,\n",
    "          random_state=42069)\n",
    "\n",
    "for index_fold, (index_train, index_val) in enumerate(kf.split(x_train, y_train)):\n",
    "    x_train_f = x_train[index_train]\n",
    "    y_train_f = y_train[index_train]\n",
    "    \n",
    "    x_val_f = x_train[index_val]\n",
    "    y_val_f = y_train[index_val]\n",
    "    \n",
    "    # train\n",
    "    model.fit(x_train_f, y_train_f, batch_size=256, epochs=16, verbose=1, validation_data=(x_val_f, y_val_f))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # compute ROC-AUC score\n",
    "    pred_val = model.predict([x_val_f], batch_size=512)\n",
    "    \n",
    "    score_auc = sklearn.metrics.roc_auc_score(y_val_f, pred_val)\n",
    "    scores.append(score_auc)\n",
    "    \n",
    "    print('Fold {}: score={}'.format(index_fold, score_auc))\n",
    "    \n",
    "    \n",
    "print('Average AUC score: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
