{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using attention model\n",
    "\n",
    "Reference: https://www.kaggle.com/truocpham/oob-cuda-gru-attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import keras\n",
    "\n",
    "#### BEGIN Attention Model ####\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "#### END Attention Model ####\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train = './datasets/train.json'\n",
    "filename_test = './datasets/test.json'\n",
    "\n",
    "train = pd.read_json(filename_train)\n",
    "test = pd.read_json(filename_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>is_turkey</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "      <th>vid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>kDCk3hLIVXo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>DPcGzqHoo7Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>7yM63MTHh5k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...</td>\n",
       "      <td>520</td>\n",
       "      <td>1</td>\n",
       "      <td>510</td>\n",
       "      <td>luG3RmUAxxM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PIm3cjxTpOk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     audio_embedding  \\\n",
       "0  [[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...   \n",
       "1  [[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...   \n",
       "2  [[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...   \n",
       "3  [[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...   \n",
       "4  [[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...   \n",
       "\n",
       "   end_time_seconds_youtube_clip  is_turkey  start_time_seconds_youtube_clip  \\\n",
       "0                             70          0                               60   \n",
       "1                             40          1                               30   \n",
       "2                            240          1                              230   \n",
       "3                            520          1                              510   \n",
       "4                             10          0                                0   \n",
       "\n",
       "        vid_id  \n",
       "0  kDCk3hLIVXo  \n",
       "1  DPcGzqHoo7Y  \n",
       "2  7yM63MTHh5k  \n",
       "3  luG3RmUAxxM  \n",
       "4  PIm3cjxTpOk  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrive Audio Embedding and Flatten it into 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.DataFrame(list(train['audio_embedding'].map(lambda x: chain.from_iterable(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195, 1280)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1270</th>\n",
       "      <th>1271</th>\n",
       "      <th>1272</th>\n",
       "      <th>1273</th>\n",
       "      <th>1274</th>\n",
       "      <th>1275</th>\n",
       "      <th>1276</th>\n",
       "      <th>1277</th>\n",
       "      <th>1278</th>\n",
       "      <th>1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172</td>\n",
       "      <td>34</td>\n",
       "      <td>216</td>\n",
       "      <td>110</td>\n",
       "      <td>208</td>\n",
       "      <td>46</td>\n",
       "      <td>95</td>\n",
       "      <td>66</td>\n",
       "      <td>161</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169</td>\n",
       "      <td>20</td>\n",
       "      <td>165</td>\n",
       "      <td>102</td>\n",
       "      <td>205</td>\n",
       "      <td>62</td>\n",
       "      <td>110</td>\n",
       "      <td>103</td>\n",
       "      <td>211</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148</td>\n",
       "      <td>8</td>\n",
       "      <td>138</td>\n",
       "      <td>60</td>\n",
       "      <td>237</td>\n",
       "      <td>48</td>\n",
       "      <td>121</td>\n",
       "      <td>108</td>\n",
       "      <td>145</td>\n",
       "      <td>177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>88</td>\n",
       "      <td>171</td>\n",
       "      <td>71</td>\n",
       "      <td>47</td>\n",
       "      <td>90</td>\n",
       "      <td>179</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162</td>\n",
       "      <td>17</td>\n",
       "      <td>187</td>\n",
       "      <td>111</td>\n",
       "      <td>211</td>\n",
       "      <td>105</td>\n",
       "      <td>92</td>\n",
       "      <td>67</td>\n",
       "      <td>203</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  1270  \\\n",
       "0   172    34   216   110   208    46    95    66   161   125  ...   0.0   \n",
       "1   169    20   165   102   205    62   110   103   211   187  ...   0.0   \n",
       "2   148     8   138    60   237    48   121   108   145   177  ...   0.0   \n",
       "3   151     0   162    88   171    71    47    90   179   190  ...   0.0   \n",
       "4   162    17   187   111   211   105    92    67   203   152  ...  62.0   \n",
       "\n",
       "    1271   1272   1273   1274   1275   1276   1277   1278   1279  \n",
       "0  135.0  133.0  151.0    0.0    3.0  206.0  101.0  104.0  255.0  \n",
       "1    0.0  119.0  205.0   27.0  151.0  226.0   44.0    0.0  255.0  \n",
       "2   62.0   79.0  204.0    0.0   74.0  243.0  255.0   95.0  255.0  \n",
       "3  255.0  207.0   52.0  178.0  129.0  186.0    0.0    0.0  255.0  \n",
       "4  224.0   15.0  172.0    0.0    2.0  255.0  144.0   34.0  255.0  \n",
       "\n",
       "[5 rows x 1280 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check whether NULL Cell exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = [k for k in train['audio_embedding']]\n",
    "test_data = test['audio_embedding'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195\n",
      "1196\n"
     ]
    }
   ],
   "source": [
    "print(len(xtrain))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = train['is_turkey'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Min/Max Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(features) for features in xtrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([len(features) for features in xtrain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pad audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(xtrain, maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195, 10, 128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(x_train).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert ytrain to np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delcare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 10, 128)           512       \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 10, 256)           197376    \n",
      "_________________________________________________________________\n",
      "attention_4 (Attention)      (None, 256)               266       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 198,411\n",
      "Trainable params: 198,155\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# def get_model(input_dim, hidden_size=64, fc1_size=10, output_size=1, lr=1e-3):\n",
    "    \n",
    "#     # output shape = (None, seq_length, feature_size)\n",
    "#     inputs = keras.layers.Input(input_dim[1:])\n",
    "\n",
    "#     # output shape = (None, seq_length, hidden_size)\n",
    "#     x_rnn = keras.layers.GRU(units=hidden_size)(inputs)\n",
    "    \n",
    "#     # output shape = (None, fc1_size)\n",
    "#     x_attention = Attention(fc1_size)(x_rnn)\n",
    "    \n",
    "#     # output shape = (None, 1)\n",
    "#     outputs = keras.layers.Dense(output_size, activation='sigmoid')(x_attention)\n",
    "    \n",
    "#     model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "#     optimizer = keras.optimizers.Adam(lr=lr)\n",
    "    \n",
    "#     model.compile(loss='binary_crossentropy',\n",
    "#                   optimizer=optimizer,\n",
    "#                  metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(10, 128)))\n",
    "#     model.add(Bidirectional(RNN(64, activation='relu', return_sequences=True)))\n",
    "    model.add(Bidirectional(GRU(128, dropout=0.4, recurrent_dropout=0.4, activation='relu', return_sequences=True)))\n",
    "    model.add(Attention(10))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "input_dim = x_train.shape\n",
    "# model = get_model(input_dim)\n",
    "model = get_model()\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-Fold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1074 samples, validate on 121 samples\n",
      "Epoch 1/16\n",
      "1074/1074 [==============================] - 2s 2ms/step - loss: 0.6147 - acc: 0.6620 - val_loss: 0.3460 - val_acc: 0.9174\n",
      "Epoch 2/16\n",
      "1074/1074 [==============================] - 0s 389us/step - loss: 0.3145 - acc: 0.9134 - val_loss: 0.2029 - val_acc: 0.9421\n",
      "Epoch 3/16\n",
      "1074/1074 [==============================] - 0s 390us/step - loss: 0.2053 - acc: 0.9348 - val_loss: 0.1550 - val_acc: 0.9504\n",
      "Epoch 4/16\n",
      "1074/1074 [==============================] - 0s 399us/step - loss: 0.1614 - acc: 0.9348 - val_loss: 0.1430 - val_acc: 0.9587\n",
      "Epoch 5/16\n",
      "1074/1074 [==============================] - 0s 392us/step - loss: 0.1442 - acc: 0.9432 - val_loss: 0.1412 - val_acc: 0.9587\n",
      "Epoch 6/16\n",
      "1074/1074 [==============================] - 0s 403us/step - loss: 0.1415 - acc: 0.9451 - val_loss: 0.1386 - val_acc: 0.9587\n",
      "Epoch 7/16\n",
      "1074/1074 [==============================] - 0s 380us/step - loss: 0.1215 - acc: 0.9544 - val_loss: 0.1363 - val_acc: 0.9587\n",
      "Epoch 8/16\n",
      "1074/1074 [==============================] - 0s 389us/step - loss: 0.1232 - acc: 0.9488 - val_loss: 0.1336 - val_acc: 0.9587\n",
      "Epoch 9/16\n",
      "1074/1074 [==============================] - 0s 398us/step - loss: 0.1137 - acc: 0.9572 - val_loss: 0.1327 - val_acc: 0.9504\n",
      "Epoch 10/16\n",
      "1074/1074 [==============================] - 0s 386us/step - loss: 0.1077 - acc: 0.9618 - val_loss: 0.1303 - val_acc: 0.9504\n",
      "Epoch 11/16\n",
      "1074/1074 [==============================] - 0s 398us/step - loss: 0.1005 - acc: 0.9637 - val_loss: 0.1286 - val_acc: 0.9504\n",
      "Epoch 12/16\n",
      "1074/1074 [==============================] - 0s 395us/step - loss: 0.0983 - acc: 0.9590 - val_loss: 0.1281 - val_acc: 0.9504\n",
      "Epoch 13/16\n",
      "1074/1074 [==============================] - 0s 387us/step - loss: 0.0990 - acc: 0.9665 - val_loss: 0.1296 - val_acc: 0.9504\n",
      "Epoch 14/16\n",
      "1074/1074 [==============================] - 0s 390us/step - loss: 0.0881 - acc: 0.9655 - val_loss: 0.1320 - val_acc: 0.9504\n",
      "Epoch 15/16\n",
      "1074/1074 [==============================] - 0s 382us/step - loss: 0.0919 - acc: 0.9702 - val_loss: 0.1329 - val_acc: 0.9504\n",
      "Epoch 16/16\n",
      "1074/1074 [==============================] - 0s 389us/step - loss: 0.0869 - acc: 0.9683 - val_loss: 0.1329 - val_acc: 0.9504\n",
      "\n",
      "Fold 0: score=0.9901408450704225\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/16\n",
      "1075/1075 [==============================] - 0s 387us/step - loss: 0.0918 - acc: 0.9609 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1075/1075 [==============================] - 0s 407us/step - loss: 0.0977 - acc: 0.9647 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1075/1075 [==============================] - 0s 384us/step - loss: 0.0961 - acc: 0.9656 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1075/1075 [==============================] - 0s 401us/step - loss: 0.0841 - acc: 0.9684 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1075/1075 [==============================] - 0s 394us/step - loss: 0.0899 - acc: 0.9702 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1075/1075 [==============================] - 0s 389us/step - loss: 0.0762 - acc: 0.9721 - val_loss: 0.0211 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1075/1075 [==============================] - 0s 405us/step - loss: 0.0808 - acc: 0.9656 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1075/1075 [==============================] - 0s 392us/step - loss: 0.0771 - acc: 0.9730 - val_loss: 0.0202 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1075/1075 [==============================] - 0s 390us/step - loss: 0.0770 - acc: 0.9693 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1075/1075 [==============================] - 0s 392us/step - loss: 0.0722 - acc: 0.9749 - val_loss: 0.0221 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1075/1075 [==============================] - 0s 388us/step - loss: 0.0774 - acc: 0.9730 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1075/1075 [==============================] - 0s 392us/step - loss: 0.0693 - acc: 0.9740 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1075/1075 [==============================] - 0s 399us/step - loss: 0.0632 - acc: 0.9814 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1075/1075 [==============================] - 0s 394us/step - loss: 0.0622 - acc: 0.9833 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1075/1075 [==============================] - 0s 396us/step - loss: 0.0609 - acc: 0.9786 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1075/1075 [==============================] - 0s 388us/step - loss: 0.0681 - acc: 0.9777 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "\n",
      "Fold 1: score=1.0\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/16\n",
      "1075/1075 [==============================] - 0s 391us/step - loss: 0.0538 - acc: 0.9814 - val_loss: 0.0314 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1075/1075 [==============================] - 0s 404us/step - loss: 0.0629 - acc: 0.9758 - val_loss: 0.0269 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1075/1075 [==============================] - 0s 397us/step - loss: 0.0547 - acc: 0.9805 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1075/1075 [==============================] - 0s 393us/step - loss: 0.0453 - acc: 0.9888 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1075/1075 [==============================] - 0s 391us/step - loss: 0.0491 - acc: 0.9833 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1075/1075 [==============================] - 0s 395us/step - loss: 0.0507 - acc: 0.9823 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1075/1075 [==============================] - 0s 393us/step - loss: 0.0411 - acc: 0.9860 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1075/1075 [==============================] - 0s 390us/step - loss: 0.0415 - acc: 0.9898 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1075/1075 [==============================] - 0s 395us/step - loss: 0.0445 - acc: 0.9870 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1075/1075 [==============================] - 0s 387us/step - loss: 0.0495 - acc: 0.9842 - val_loss: 0.0374 - val_acc: 0.9833\n",
      "Epoch 11/16\n",
      "1075/1075 [==============================] - 0s 386us/step - loss: 0.0459 - acc: 0.9795 - val_loss: 0.0421 - val_acc: 0.9833\n",
      "Epoch 12/16\n",
      "1075/1075 [==============================] - 0s 391us/step - loss: 0.0386 - acc: 0.9851 - val_loss: 0.0525 - val_acc: 0.9833\n",
      "Epoch 13/16\n",
      "1075/1075 [==============================] - 0s 393us/step - loss: 0.0355 - acc: 0.9898 - val_loss: 0.0411 - val_acc: 0.9833\n",
      "Epoch 14/16\n",
      "1075/1075 [==============================] - 0s 399us/step - loss: 0.0359 - acc: 0.9870 - val_loss: 0.0270 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1075/1075 [==============================] - 0s 390us/step - loss: 0.0329 - acc: 0.9870 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1075/1075 [==============================] - 0s 389us/step - loss: 0.0327 - acc: 0.9916 - val_loss: 0.0267 - val_acc: 1.0000\n",
      "\n",
      "Fold 2: score=1.0\n",
      "Train on 1075 samples, validate on 120 samples\n",
      "Epoch 1/16\n",
      "1075/1075 [==============================] - 0s 389us/step - loss: 0.0284 - acc: 0.9888 - val_loss: 0.0179 - val_acc: 0.9917\n",
      "Epoch 2/16\n",
      "1075/1075 [==============================] - 0s 401us/step - loss: 0.0312 - acc: 0.9888 - val_loss: 0.0179 - val_acc: 0.9917\n",
      "Epoch 3/16\n",
      "1075/1075 [==============================] - 0s 394us/step - loss: 0.0335 - acc: 0.9870 - val_loss: 0.0159 - val_acc: 0.9917\n",
      "Epoch 4/16\n",
      "1075/1075 [==============================] - 0s 394us/step - loss: 0.0329 - acc: 0.9870 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1075/1075 [==============================] - 0s 401us/step - loss: 0.0387 - acc: 0.9860 - val_loss: 0.0167 - val_acc: 0.9917\n",
      "Epoch 6/16\n",
      "1075/1075 [==============================] - 0s 387us/step - loss: 0.0229 - acc: 0.9907 - val_loss: 0.0202 - val_acc: 0.9917\n",
      "Epoch 7/16\n",
      "1075/1075 [==============================] - 0s 412us/step - loss: 0.0237 - acc: 0.9926 - val_loss: 0.0210 - val_acc: 0.9917\n",
      "Epoch 8/16\n",
      "1075/1075 [==============================] - 0s 393us/step - loss: 0.0233 - acc: 0.9907 - val_loss: 0.0196 - val_acc: 0.9917\n",
      "Epoch 9/16\n",
      "1075/1075 [==============================] - 0s 396us/step - loss: 0.0184 - acc: 0.9963 - val_loss: 0.0186 - val_acc: 0.9917\n",
      "Epoch 10/16\n",
      "1075/1075 [==============================] - 0s 406us/step - loss: 0.0247 - acc: 0.9907 - val_loss: 0.0216 - val_acc: 0.9917\n",
      "Epoch 11/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075/1075 [==============================] - 0s 392us/step - loss: 0.0266 - acc: 0.9926 - val_loss: 0.0280 - val_acc: 0.9917\n",
      "Epoch 12/16\n",
      "1075/1075 [==============================] - 0s 397us/step - loss: 0.0259 - acc: 0.9907 - val_loss: 0.0318 - val_acc: 0.9917\n",
      "Epoch 13/16\n",
      "1075/1075 [==============================] - 0s 402us/step - loss: 0.0257 - acc: 0.9916 - val_loss: 0.0320 - val_acc: 0.9917\n",
      "Epoch 14/16\n",
      "1075/1075 [==============================] - 0s 387us/step - loss: 0.0204 - acc: 0.9926 - val_loss: 0.0294 - val_acc: 0.9917\n",
      "Epoch 15/16\n",
      "1075/1075 [==============================] - 0s 398us/step - loss: 0.0176 - acc: 0.9953 - val_loss: 0.0299 - val_acc: 0.9917\n",
      "Epoch 16/16\n",
      "1075/1075 [==============================] - 0s 397us/step - loss: 0.0223 - acc: 0.9935 - val_loss: 0.0320 - val_acc: 0.9917\n",
      "\n",
      "Fold 3: score=0.9994251221615407\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 390us/step - loss: 0.0180 - acc: 0.9963 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 400us/step - loss: 0.0171 - acc: 0.9935 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 385us/step - loss: 0.0199 - acc: 0.9935 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 396us/step - loss: 0.0228 - acc: 0.9935 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 385us/step - loss: 0.0163 - acc: 0.9963 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 388us/step - loss: 0.0196 - acc: 0.9926 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 394us/step - loss: 0.0135 - acc: 0.9972 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0195 - acc: 0.9954 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 395us/step - loss: 0.0205 - acc: 0.9944 - val_loss: 0.0182 - val_acc: 0.9916\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 406us/step - loss: 0.0232 - acc: 0.9926 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 390us/step - loss: 0.0122 - acc: 0.9972 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 399us/step - loss: 0.0133 - acc: 0.9972 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 401us/step - loss: 0.0161 - acc: 0.9954 - val_loss: 0.0175 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 399us/step - loss: 0.0095 - acc: 0.9981 - val_loss: 0.0183 - val_acc: 0.9916\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 397us/step - loss: 0.0190 - acc: 0.9935 - val_loss: 0.0192 - val_acc: 0.9916\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 391us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "\n",
      "Fold 4: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 390us/step - loss: 0.0151 - acc: 0.9954 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 390us/step - loss: 0.0145 - acc: 0.9954 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 391us/step - loss: 0.0166 - acc: 0.9944 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 394us/step - loss: 0.0142 - acc: 0.9935 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 388us/step - loss: 0.0106 - acc: 0.9972 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0140 - acc: 0.9954 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 386us/step - loss: 0.0107 - acc: 0.9972 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 401us/step - loss: 0.0107 - acc: 0.9963 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 400us/step - loss: 0.0104 - acc: 0.9954 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 385us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 398us/step - loss: 0.0145 - acc: 0.9972 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 396us/step - loss: 0.0077 - acc: 0.9981 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0143 - acc: 0.9944 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 383us/step - loss: 0.0119 - acc: 0.9972 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 392us/step - loss: 0.0116 - acc: 0.9981 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "\n",
      "Fold 5: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 394us/step - loss: 0.0133 - acc: 0.9944 - val_loss: 6.1188e-04 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 399us/step - loss: 0.0179 - acc: 0.9935 - val_loss: 5.2636e-04 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 400us/step - loss: 0.0059 - acc: 0.9981 - val_loss: 5.4015e-04 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 392us/step - loss: 0.0104 - acc: 0.9963 - val_loss: 5.5303e-04 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 399us/step - loss: 0.0083 - acc: 0.9981 - val_loss: 6.5389e-04 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 385us/step - loss: 0.0107 - acc: 0.9963 - val_loss: 9.8992e-04 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 386us/step - loss: 0.0084 - acc: 0.9991 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 403us/step - loss: 0.0124 - acc: 0.9972 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0099 - acc: 0.9972 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0079 - acc: 0.9981 - val_loss: 9.0359e-04 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 394us/step - loss: 0.0050 - acc: 0.9991 - val_loss: 9.4219e-04 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0077 - acc: 0.9972 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 392us/step - loss: 0.0132 - acc: 0.9963 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 397us/step - loss: 0.0114 - acc: 0.9954 - val_loss: 9.0373e-04 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 392us/step - loss: 0.0071 - acc: 0.9981 - val_loss: 7.8728e-04 - val_acc: 1.0000\n",
      "\n",
      "Fold 6: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 383us/step - loss: 0.0157 - acc: 0.9944 - val_loss: 4.5784e-04 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 401us/step - loss: 0.0079 - acc: 0.9981 - val_loss: 4.8132e-04 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0089 - acc: 0.9981 - val_loss: 5.6570e-04 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 407us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 4.7290e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 396us/step - loss: 0.0091 - acc: 0.9972 - val_loss: 4.8713e-04 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 390us/step - loss: 0.0086 - acc: 0.9981 - val_loss: 6.1685e-04 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0066 - acc: 0.9981 - val_loss: 6.2527e-04 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 385us/step - loss: 0.0055 - acc: 0.9981 - val_loss: 6.0206e-04 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 405us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 5.5121e-04 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 400us/step - loss: 0.0077 - acc: 0.9981 - val_loss: 4.5831e-04 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 390us/step - loss: 0.0081 - acc: 0.9972 - val_loss: 4.7899e-04 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 382us/step - loss: 0.0060 - acc: 0.9981 - val_loss: 5.0898e-04 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 388us/step - loss: 0.0043 - acc: 0.9991 - val_loss: 5.0808e-04 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 394us/step - loss: 0.0056 - acc: 0.9991 - val_loss: 4.5991e-04 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 401us/step - loss: 0.0055 - acc: 0.9991 - val_loss: 4.8356e-04 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 391us/step - loss: 0.0078 - acc: 0.9981 - val_loss: 4.2587e-04 - val_acc: 1.0000\n",
      "\n",
      "Fold 7: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0071 - acc: 0.9963 - val_loss: 2.3543e-04 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 388us/step - loss: 0.0055 - acc: 0.9981 - val_loss: 2.3666e-04 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0133 - acc: 0.9954 - val_loss: 2.6121e-04 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 399us/step - loss: 0.0046 - acc: 0.9981 - val_loss: 3.0797e-04 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 391us/step - loss: 0.0056 - acc: 0.9981 - val_loss: 3.4727e-04 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0089 - acc: 0.9972 - val_loss: 3.9782e-04 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 384us/step - loss: 0.0042 - acc: 0.9991 - val_loss: 4.2898e-04 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0047 - acc: 0.9981 - val_loss: 4.5674e-04 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 384us/step - loss: 0.0070 - acc: 0.9991 - val_loss: 4.5807e-04 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 402us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 4.2641e-04 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0052 - acc: 0.9991 - val_loss: 4.0796e-04 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 399us/step - loss: 0.0048 - acc: 0.9981 - val_loss: 3.7279e-04 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 3.5316e-04 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 396us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 3.8765e-04 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 396us/step - loss: 0.0105 - acc: 0.9954 - val_loss: 4.0765e-04 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 392us/step - loss: 0.0040 - acc: 0.9981 - val_loss: 5.0187e-04 - val_acc: 1.0000\n",
      "\n",
      "Fold 8: score=1.0\n",
      "Train on 1076 samples, validate on 119 samples\n",
      "Epoch 1/16\n",
      "1076/1076 [==============================] - 0s 393us/step - loss: 0.0072 - acc: 0.9972 - val_loss: 4.7891e-04 - val_acc: 1.0000\n",
      "Epoch 2/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0087 - acc: 0.9972 - val_loss: 6.4289e-04 - val_acc: 1.0000\n",
      "Epoch 3/16\n",
      "1076/1076 [==============================] - 0s 386us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.1479e-04 - val_acc: 1.0000\n",
      "Epoch 4/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 2.9416e-04 - val_acc: 1.0000\n",
      "Epoch 5/16\n",
      "1076/1076 [==============================] - 0s 385us/step - loss: 0.0056 - acc: 0.9981 - val_loss: 3.1558e-04 - val_acc: 1.0000\n",
      "Epoch 6/16\n",
      "1076/1076 [==============================] - 0s 386us/step - loss: 0.0039 - acc: 0.9991 - val_loss: 3.7565e-04 - val_acc: 1.0000\n",
      "Epoch 7/16\n",
      "1076/1076 [==============================] - 0s 386us/step - loss: 0.0048 - acc: 0.9991 - val_loss: 3.0427e-04 - val_acc: 1.0000\n",
      "Epoch 8/16\n",
      "1076/1076 [==============================] - 0s 382us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 2.2648e-04 - val_acc: 1.0000\n",
      "Epoch 9/16\n",
      "1076/1076 [==============================] - 0s 386us/step - loss: 0.0078 - acc: 0.9991 - val_loss: 2.1346e-04 - val_acc: 1.0000\n",
      "Epoch 10/16\n",
      "1076/1076 [==============================] - 0s 404us/step - loss: 0.0064 - acc: 0.9991 - val_loss: 2.6601e-04 - val_acc: 1.0000\n",
      "Epoch 11/16\n",
      "1076/1076 [==============================] - 0s 382us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 4.7392e-04 - val_acc: 1.0000\n",
      "Epoch 12/16\n",
      "1076/1076 [==============================] - 0s 384us/step - loss: 0.0070 - acc: 0.9981 - val_loss: 5.4889e-04 - val_acc: 1.0000\n",
      "Epoch 13/16\n",
      "1076/1076 [==============================] - 0s 383us/step - loss: 0.0047 - acc: 0.9991 - val_loss: 5.1863e-04 - val_acc: 1.0000\n",
      "Epoch 14/16\n",
      "1076/1076 [==============================] - 0s 389us/step - loss: 0.0042 - acc: 0.9981 - val_loss: 4.6093e-04 - val_acc: 1.0000\n",
      "Epoch 15/16\n",
      "1076/1076 [==============================] - 0s 387us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 3.5573e-04 - val_acc: 1.0000\n",
      "Epoch 16/16\n",
      "1076/1076 [==============================] - 0s 402us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.8749e-04 - val_acc: 1.0000\n",
      "\n",
      "Fold 9: score=1.0\n",
      "Average AUC score: 0.9989565967231963\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores = []\n",
    "\n",
    "# sklearn.model_selection.KFold\n",
    "kf = StratifiedKFold(n_splits=10,\n",
    "          shuffle=True,\n",
    "          random_state=42069)\n",
    "\n",
    "for index_fold, (index_train, index_val) in enumerate(kf.split(x_train, y_train)):\n",
    "    x_train_f = x_train[index_train]\n",
    "    y_train_f = y_train[index_train]\n",
    "    \n",
    "    x_val_f = x_train[index_val]\n",
    "    y_val_f = y_train[index_val]\n",
    "    \n",
    "    # train\n",
    "    model.fit(x_train_f, y_train_f, batch_size=256, epochs=16, verbose=1, validation_data=(x_val_f, y_val_f))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # compute ROC-AUC score\n",
    "    pred_val = model.predict([x_val_f], batch_size=512)\n",
    "    \n",
    "    score_auc = sklearn.metrics.roc_auc_score(y_val_f, pred_val)\n",
    "    scores.append(score_auc)\n",
    "    \n",
    "    print('Fold {}: score={}'.format(index_fold, score_auc))\n",
    "    \n",
    "    \n",
    "print('Average AUC score: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
